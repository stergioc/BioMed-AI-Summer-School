{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0BUr_7GVHZT"
      },
      "source": [
        "<table>\n",
        "<tr height=\"150px\">\n",
        "<th>\n",
        "<img height=\"80px\" margin=\"20px\" src='https://www.archimedesai.gr/images/logo_en.svg' />\n",
        "</th>\n",
        "<th>\n",
        "<img height=\"150px\" src='https://stergioc.github.io/assets/img/logos.png' />\n",
        "</th>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "<h1>Introduction to Deep Learning (Hands-on Tutorial)</h1>\n",
        "<h3>Maria Vakalopoulou & Stergios CHRISTODOULIDIS</h3>\n",
        "\n",
        "[![ML-tutorial](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/stergioc/BioMed-AI-Summer-School/blob/master/DL/dl-tutorial.ipynb)\n",
        "\n",
        "In this tutorial, we will code a neural network to perform segmentation of tumours in brain images. The data are retrieved from the [BraTS](https://www.med.upenn.edu/cbica/brats2019/data.html) dataset and have been already lightly preprocessed for this tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB4W-Jw9VHZn"
      },
      "source": [
        "# **1. Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13YDHJHyC8td",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torch.utils.tensorboard\n",
        "import torchvision\n",
        "import torchvision.transforms\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import skimage.transform\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn.model_selection as model_selection\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install SimpleITK\n",
        "import SimpleITK as sitk\n",
        "\n",
        "!pip install tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t2qfPU3VHZx"
      },
      "source": [
        "# **2. Database**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO_00VNxVqB_"
      },
      "source": [
        "## 2.a. Download the database\n",
        "\n",
        "Run the following cell to download the database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPENhQdf3QrC",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# A large portion of the BraTS data (~2GB) of data will be downloaded with\n",
        "# this command, it should take about ~3 minutes.\n",
        "!wget https://nextcloud.centralesupelec.fr/s/YXd3S8sAYbjaz2Z/download/dl-tutorial-data.zip\n",
        "!unzip -q dl-tutorial-data.zip -d GEP1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io16YVeDYE0G",
        "tags": []
      },
      "source": [
        "## 2.b. Overview of the database\n",
        "\n",
        "The data is stored in the folder `/GEP1/`.\n",
        "\n",
        "In that folder you will find:\n",
        "> The `origin_data` folder: contains 4 patients.\n",
        ">- For each patient, you will find a whole volume per modality in nifti format.\n",
        ">- Each volume has a shape `(155, 192, 192)`\n",
        "\n",
        "> The `data` folder: contains 336 patients.\n",
        ">- Images in that folder have underwent some preprocessing and have now a shape `(78, 96, 96)`. This will make training of deep learning models faster and less greedy memory-wise.\n",
        ">- For a patient `BraTS19_EXAMPLE`, you will have a corresponding folder `/GEP1/data/BraTS19_EXAMPLE`. Inside this folder, you will have nifti files (`.nii.gz`) for each modality and each z slice. .\n",
        ">- There are 78 slices per volume, i.e. 78 slices per modality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJZ7vV9UVHZ7"
      },
      "outputs": [],
      "source": [
        "# The data is store in the folder /GEP1/\n",
        "data_path = './GEP1/data/'\n",
        "original_data_path = './GEP1/origin_data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPUuRxOHVHaA",
        "tags": []
      },
      "source": [
        "### **i. Inside of the database**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSV6BYfEVHaD",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Original data\n",
        "print(\"Content of the folder:\\n\", os.listdir(original_data_path))\n",
        "patient = \"BraTS19_TCIA01_131_1\"\n",
        "print(\"Content of a patient's folder:\\n\", os.listdir(original_data_path + patient))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE1SY6hSVHaH",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Processed data\n",
        "files = os.listdir(data_path) # All the files in the folder /GEP1/data/\n",
        "print('Content of the folder {} \\n: {}'.format(data_path, files[:5]))\n",
        "# print('Number of files for each patient : {}'.format(len(os.listdir(data_path + files[0])) ))\n",
        "print('Number of patients in {} : {}'.format(data_path, len(files)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JsQbnkhVHaK",
        "tags": []
      },
      "source": [
        "### **ii. Patient's folder**\n",
        "\n",
        "For each patient, we have 4 modalities and the segmentation:\n",
        "\n",
        "- t1\n",
        "- t2\n",
        "- flair\n",
        "- t1ce (gado)\n",
        "- segmentation\n",
        "\n",
        "For each modality, you also have a file for each slice along the Z axis.\n",
        "\n",
        "Each patient has **78 slices** per modality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqWxq524VHaM",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "modalities = ['t1', 't2', 't1ce', 'flair', 'seg']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yI1kupGTVHaS",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "patient = 'BraTS19_2013_20_1'\n",
        "patient_path = os.path.join(data_path, patient)\n",
        "patient_files = os.listdir(patient_path)\n",
        "patient_files[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLQ4JtRjVHaV",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Filter for the Flair modality\n",
        "\"\"\"\n",
        "\n",
        "flair_modality_files = sorted([e for e in patient_files if 'flair' in e])\n",
        "print(\"Number of Z slices:\", len(flair_modality_files))\n",
        "flair_modality_files[-5:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmGMQt78VHaY",
        "tags": []
      },
      "source": [
        "### **iii. SimpleITK tutorial**\n",
        "\n",
        "Use the `SimpleITK` Python package in order to read the nifti files of the database.\n",
        "\n",
        "To open a a nifti image:\n",
        "\n",
        "        image = sitk.ReadImage(image_path)\n",
        "\n",
        "Using this package, you can access relevant and physical information about the image:\n",
        "- spacing: `image.GetSpacing()`\n",
        "- direction: `image.GetDirection()`\n",
        "- origin: `image.GetOrigin()`\n",
        "- size: `image.GetSize()`\n",
        "- metadata: `image.GetMetaDataKeys()`\n",
        "- access the value of a pixel: `image.GetPixel(pixel_x, pixel_y, pixel_z)`\n",
        "\n",
        "You can also convert the `sitk` image into a `numpy` array:\n",
        "\n",
        "        array = sitk.GetArrayFromImage(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPDUJ-IhVHaZ",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "### START CODE HERE ###\n",
        "#img = ...\n",
        "#array = ...\n",
        "### END CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrcfaqwSVHah",
        "tags": []
      },
      "source": [
        "### **iv. Comparison between original data and preprocessed data.**\n",
        "\n",
        "In order to accelerate the calculation time and have good results quickly, the original images of the dataset of shape `(155, 240, 240)` have been preprocessed according to the following steps:\n",
        "- Cropped the images to a shape of `(155, 192, 192)`\n",
        "- Downsampled the images by interpolation of scale 0.5 (https://scikit-image.org/docs/dev/auto_examples/transform/plot_rescale.html) to a shape of `(78, 96, 96)`\n",
        "- Saved all the Z slices **independently** in a new array of shape `(96, 96)`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wswI0m1NVHai",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "patient = 'BraTS19_CBICA_ANP_1'\n",
        "\n",
        "# Define the image path in the original data\n",
        "z = 3\n",
        "modality = 'flair'\n",
        "patient_folder = os.path.join(original_data_path, patient)\n",
        "image_name = \"{patient}_{modality}.nii.gz\".format(patient=patient, modality=modality)\n",
        "image_path = os.path.join(patient_folder, image_name)\n",
        "\n",
        "# We use the librairy sitk to open the nifti images\n",
        "image = sitk.ReadImage(image_path)\n",
        "orig_array = sitk.GetArrayFromImage(image)\n",
        "print('Original array shape : {}'.format(orig_array.shape))\n",
        "\n",
        "# open corresponding preprocessed data slice\n",
        "patient_folder = os.path.join(data_path, patient)\n",
        "z_slice = 35\n",
        "path = os.path.join(patient_folder, \"{patient}_{modality}_z_{z_slice}.nii.gz\".format(patient=patient, modality=modality, z_slice=z_slice))\n",
        "image = sitk.ReadImage(path)\n",
        "processed_array = sitk.GetArrayFromImage(image)\n",
        "print('Processed array shape : {}'.format(processed_array.shape))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(orig_array[z_slice*2, :, :], cmap='gray')\n",
        "plt.title('Original array')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(processed_array, cmap='gray')\n",
        "plt.title('Processed array')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXW-yIHeVHak",
        "tags": []
      },
      "source": [
        "### **iv. Visualize all modalities**\n",
        "\n",
        "Consider a patient in the `data` folder. Plot each modality side by side, by iterating over the number of slices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7OYGY8_VHal",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Go over each Z slice\n",
        "z=46\n",
        "\n",
        "f, axes = plt.subplots(1, 5, figsize=(20, 6))\n",
        "# Plot each modality for that slice\n",
        "for i, modality in enumerate(modalities):\n",
        "    colormap = None if i==4 else 'gray'\n",
        "    # Fetch the modality-slice file and open using SimpleITK\n",
        "    file_path = data_path + f\"{patient}/{patient}_{modality}_z_{z}.nii.gz\"\n",
        "    slice = sitk.GetArrayFromImage(sitk.ReadImage(file_path))\n",
        "\n",
        "    # Plot the slice\n",
        "    axes[i].set_title(modality)\n",
        "    axes[i].imshow(slice, cmap=colormap)\n",
        "\n",
        "plt.suptitle(\"Slice {}/{}\".format(z+1, len(flair_modality_files)), y=0.85)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfFJKex5VHan",
        "tags": []
      },
      "source": [
        "## 2.c. Creating the train, validation and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWzV-qrfZ0nk",
        "tags": []
      },
      "source": [
        "\n",
        "The train, validation and test split are stored in the folder `/GEP1/datasets`. For each split, you will have a text file indicating the list of patients.\n",
        "\n",
        "Execute the following code to :\n",
        "*   Load the train, validation and test set.\n",
        "*   Print the first 5 patients of the train set.\n",
        "*   Print the length of the train, validation and test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1nxaDK_Z1AS",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "datasets_path = './GEP1/datasets/'\n",
        "\n",
        "train_set = np.loadtxt(datasets_path + 'train.txt', dtype=str)\n",
        "validation_set = np.loadtxt(datasets_path + 'val.txt', dtype=str)\n",
        "test_set = np.loadtxt(datasets_path + 'test.txt', dtype=str)\n",
        "\n",
        "# Train_set, validation_set and test_set are list of patients\n",
        "print('Train set, first 5 patients : {}\\n'.format(train_set[:5])) # Print the first 5 patients of train_set\n",
        "print('Train set length :\\t {}'.format(len(train_set)))\n",
        "print('Validation set length :\\t {}'.format(len(validation_set)))\n",
        "print('Test set length :\\t {}'.format(len(test_set)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcVUj8KuXXfN"
      },
      "source": [
        "# **3. Creation of the neural network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNVPBwaDZnFx",
        "tags": []
      },
      "source": [
        "In this part, we will implement and train a [**UNet**](https://arxiv.org/pdf/1505.04597.pdf). UNets are particularly used for segmentation tasks in medical imaging. You can study its architecture in the following figure.\n",
        "\n",
        "The UNet has two main features :\n",
        "\n",
        "1.   The size of the input image is downsampled by 2 at each block by a layer called `MaxPooling` in the **encoder part** of the model. In the **decoder part**, extracted features are upsampled progressively using a Transpose Convolution  (`ConvTranspose2d` in PyTorch).\n",
        "\n",
        "2.   Secondly in order to keep information of high resolution, we use **skip-connections** to pass information from the encoder part of the network to the decoder part.\n",
        "\n",
        "![](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qDJ20x-8jPJ"
      },
      "source": [
        "## 3.a. Create the network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjY5Q--3VHat",
        "tags": []
      },
      "source": [
        "### Exersise 1 - Implement the UNet Building blocks\n",
        "\n",
        ">Complete the following class `ConvBatchNorm`. You should use:\n",
        ">- [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
        ">- [BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjI9ZLS1VHaw",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class ConvBatchNorm(nn.Module):\n",
        "    \"\"\"This block implements the sequence: (convolution => [BN] => ReLU)\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        ### START CODE HERE ###\n",
        "        #self.conv = ...\n",
        "        #self.norm = ...\n",
        "        #self.activation = ...\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.norm(out)\n",
        "        out = self.activation(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjCygJq5VHay",
        "tags": []
      },
      "source": [
        "What does the function `_make_nConv` do ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_lwX9LuVHaz",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def _make_nConv(in_channels, out_channels, nb_Conv):\n",
        "    layers = []\n",
        "    layers.append(ConvBatchNorm(in_channels, out_channels))\n",
        "    for _ in range(nb_Conv-1):\n",
        "        layers.append(ConvBatchNorm(out_channels, out_channels))\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t_cz-28VHa0",
        "tags": []
      },
      "source": [
        ">Complete the classes:\n",
        ">- `ConvBatchNorm`\n",
        ">- `DownConvBlock`: these will be used to build the **encoder** part of the UNet.\n",
        ">- `UpConvBlock`: these are used to build the **decoder** part of the UNet.\n",
        "\n",
        ">You should use PyTorch layers such as:\n",
        ">- `MaxPool2d`,\n",
        ">- `ConvTransposed2d` or `Upsample`,\n",
        ">- `ReLU`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQJbRxlfZmAb",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class DownBlock(nn.Module):\n",
        "    \"\"\"Downscaling with maxpooling and convolutions\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, nb_Conv=2):\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.nConvs = _make_nConv(in_channels, out_channels, nb_Conv)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.maxpool(x)\n",
        "        out = self.nConvs(out)\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, nb_Conv=2):\n",
        "        self.nConvs = _make_nConv(in_channels, out_channels, nb_Conv)\n",
        "        self.last = nn.ConvTranspose2d(out_channels, in_channels,\n",
        "                                           kernel_size=3, stride=2,\n",
        "                                           padding=1, output_padding=1)\n",
        "    def forward(self, input):\n",
        "        out = self.nConvs(input)\n",
        "        out = self.last(out)\n",
        "        return out\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    \"\"\"Upscaling then conv\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, nb_Conv=2):\n",
        "        self.up = nn.Upsample(scale_factor=2)\n",
        "        self.nConvs = _make_nConv(in_channels, out_channels, nb_Conv)\n",
        "\n",
        "    def forward(self, x, skip_x):\n",
        "        ### START CODE HERE ###\n",
        "        # Note that in this function there are two inputs.\n",
        "        # Useful fuction: https://pytorch.org/docs/stable/generated/torch.cat.html\n",
        "        ### END CODE HERE ###\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK4PhCrQVHa3",
        "tags": []
      },
      "source": [
        "### **ii. UNet architecture**\n",
        "\n",
        "Here you will use the building blocks coded above to construct the full UNet architecture.\n",
        "\n",
        "- Be careful to the number of input / output channels of each block when implementing the skip connections.\n",
        "\n",
        "- Try to compare the following code with the figure. Where are the `DownConvBlock`, the `UpConvBlock` ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi_jPXtGZ1-p",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels=4, n_classes=4):\n",
        "        '''\n",
        "        n_channels : number of channels of the input.\n",
        "                        By default 4, because we have 4 modalities\n",
        "        n_labels : number of channels of the ouput.\n",
        "                      By default 4 (3 labels + 1 for the background)\n",
        "        '''\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        # Question here\n",
        "        self.inc = ConvBatchNorm(n_channels, 64)\n",
        "        self.down1 = DownBlock(64, 128, nb_Conv=2)\n",
        "        self.down2 = DownBlock(128, 256, nb_Conv=2)\n",
        "        self.down3 = DownBlock(256, 512, nb_Conv=2)\n",
        "        self.down4 = DownBlock(512, 512, nb_Conv=2)\n",
        "\n",
        "        self.Encoder = [self.down1, self.down2, self.down3, self.down4]\n",
        "\n",
        "        self.bottleneck = Bottleneck(512, 512)\n",
        "\n",
        "        self.up1 = UpBlock(1024, 256, nb_Conv=2)\n",
        "        self.up2 = UpBlock(512, 128, nb_Conv=2)\n",
        "        self.up3 = UpBlock(256, 64, nb_Conv=2)\n",
        "        self.up4 = UpBlock(128, 64, nb_Conv=2)\n",
        "\n",
        "        self.Decoder = [self.up1, self.up2, self.up3, self.up4]\n",
        "\n",
        "        self.outc = nn.Sequential(\n",
        "            nn.ConvTranspose2d(\n",
        "                64, 64, kernel_size=3,stride=2,padding=1, output_padding=1\n",
        "            ),\n",
        "            nn.Conv2d(\n",
        "                64, self.n_classes, kernel_size=3, stride=1, padding=1\n",
        "            )\n",
        "        )\n",
        "        self.last_activation = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward\n",
        "        skip_inputs = []\n",
        "        x = self.inc(x)\n",
        "\n",
        "        # Forward through encoder\n",
        "        for i, block in enumerate(self.Encoder):\n",
        "            x = block(x)\n",
        "            skip_inputs += [x]\n",
        "\n",
        "        # We are at the bottleneck.\n",
        "        bottleneck = self.bottleneck(x)\n",
        "\n",
        "        # Forward through decoder\n",
        "        skip_inputs.reverse()\n",
        "\n",
        "        decoded = bottleneck\n",
        "        for i, block in enumerate(self.Decoder):\n",
        "            # Concat with skipconnections\n",
        "            skipped = skip_inputs[i+1]\n",
        "            decoded = block(decoded, skipped)\n",
        "        out = self.last_activation(self.outc(decoded))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNtCpyZv8t8L",
        "tags": []
      },
      "source": [
        "## 3.b. Study the model\n",
        "\n",
        "> To study and debug a neural network, you can try to feed a random tensor of size `(1, 4, 96, 96)` (batch size, number of modalites, image shape) using the `torch.rand` function.\n",
        "\n",
        "> The output's shape should be the same as the input.\n",
        "\n",
        "> To better debug, you may need to modify your code to take a look at the output shape of each layer in your network .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktk3C0AWapYk",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = UNet(n_channels=4, n_classes=4)\n",
        "print(model)\n",
        "\n",
        "# Image of size 96*96 with 4 modality + batch size = 1\n",
        "x = torch.rand((1, 4, 96, 96))\n",
        "y = model(x)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyvYD-ZzAoll",
        "tags": []
      },
      "source": [
        "# **4. Dataset creation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-E8AoHtV4PG"
      },
      "source": [
        "## 4.a. Helper functions - CODE TO EXECUTE AND HIDE\n",
        "\n",
        "All the following code is needed to execute the model, but we don't ask you to implement it. You just need to execute it once. If you want, you can try to understand what the different functions are doing but it is not needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1coYIDpScNmD",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "end = '.nii.gz'\n",
        "seg_name = '_seg'\n",
        "\n",
        "def load_split(split_folder):\n",
        "    '''\n",
        "        return train, val, test split with loadtxt\n",
        "    '''\n",
        "    train_split = np.loadtxt(os.path.join(\n",
        "        split_folder, 'train.txt'), dtype=str)\n",
        "    val_split = np.loadtxt(os.path.join(split_folder, 'val.txt'), dtype=str)\n",
        "    test_split = np.loadtxt(os.path.join(split_folder, 'test.txt'), dtype=str)\n",
        "    return train_split, val_split, test_split\n",
        "\n",
        "\n",
        "def load_sitk(path):\n",
        "    return sitk.GetArrayFromImage(sitk.ReadImage(path))\n",
        "\n",
        "\n",
        "def find_z_slice(list_patient, threshold, dataframe):\n",
        "    \"\"\"\n",
        "    For each patient in list_patient, this function returns the list of slices where\n",
        "    the corresponding image is not empty\"\"\"\n",
        "\n",
        "    list_IDs = []\n",
        "    for patient in list_patient:\n",
        "        if threshold > 0:\n",
        "            condition = dataframe[patient].values >= threshold\n",
        "            z_slice = np.where(condition)[0]\n",
        "        else:\n",
        "            z_slice = range(155)\n",
        "        list_IDs += list(set([(patient, int(z//2)) for z in z_slice]))\n",
        "\n",
        "    return list_IDs\n",
        "\n",
        "\n",
        "def generate_IDs(train_split, val_split, test_split,\n",
        "                 tumor_percentage, csv_path, image_size=(240, 240)):\n",
        "\n",
        "    tumor_volume_dataframe = pd.read_csv(csv_path)\n",
        "    threshold = int(tumor_percentage * np.prod(image_size) / 100)\n",
        "\n",
        "    train_IDs, val_IDs, test_IDs = [], [], []\n",
        "    train_IDs = find_z_slice(train_split, threshold, tumor_volume_dataframe)\n",
        "    val_IDs = find_z_slice(val_split, threshold, tumor_volume_dataframe)\n",
        "    test_IDs = find_z_slice(test_split, 0, tumor_volume_dataframe)\n",
        "    return train_IDs, val_IDs, test_IDs\n",
        "\n",
        "\n",
        "def to_var(x, device):\n",
        "    if isinstance(x, np.ndarray):\n",
        "        x = torch.from_numpy(x)\n",
        "    x = x.to(device)\n",
        "    return x\n",
        "\n",
        "def to_numpy(x):\n",
        "    if not (isinstance(x, np.ndarray) or x is None):\n",
        "        if x.is_cuda:\n",
        "            x = x.data.cpu()\n",
        "        x = x.numpy()\n",
        "    return x\n",
        "\n",
        "def save_checkpoint(state, save_path):\n",
        "    '''\n",
        "        Save the current model.\n",
        "        If the model is the best model since beginning of the training\n",
        "        it will be copy\n",
        "    '''\n",
        "\n",
        "    if not os.path.isdir(save_path):\n",
        "        os.makedirs(save_path)\n",
        "\n",
        "    epoch = state['epoch']\n",
        "    val_loss = state['val_loss']\n",
        "    filename = save_path + '/' + \\\n",
        "        'model.{:02d}--{:.3f}.pth.tar'.format(epoch, val_loss)\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "def print_summary(epoch, i, nb_batch, loss, batch_time,\n",
        "                  average_loss, average_time, mode):\n",
        "    '''\n",
        "        mode = Train or Test\n",
        "    '''\n",
        "    summary = '[' + str(mode) + '] Epoch: [{0}][{1}/{2}]\\t'.format(\n",
        "        epoch, i, nb_batch)\n",
        "\n",
        "    string = ''\n",
        "    string += ('Dice Loss {:.4f} ').format(loss)\n",
        "    string += ('(Average {:.4f}) \\t').format(average_loss)\n",
        "    string += ('Batch Time {:.4f} ').format(batch_time)\n",
        "    string += ('(Average {:.4f}) \\t').format(average_time)\n",
        "\n",
        "    summary += string\n",
        "    print(summary)\n",
        "\n",
        "def plot(irms, masks=None, pred_masks=None):\n",
        "\n",
        "    kwargs = {'cmap': 'gray'}\n",
        "    fig, ax = plt.subplots(2, 3, gridspec_kw={'wspace': 0.15, 'hspace': 0.2,\n",
        "                                              'top': 0.85, 'bottom': 0.1,\n",
        "                                              'left': 0.05, 'right': 0.95},\n",
        "                           figsize=(12, 7))\n",
        "    ax[0, 0].imshow(irms[0, :, :], **kwargs)\n",
        "\n",
        "    if masks is not None:\n",
        "        masks = np.argmax(masks, axis=0)\n",
        "        ax[0, 1].imshow(masks, vmin=0, vmax=3)\n",
        "\n",
        "    if pred_masks is not None:\n",
        "        pred_masks = np.argmax(pred_masks, axis=0)\n",
        "        ax[0, 2].imshow(pred_masks, vmin=0, vmax=3)\n",
        "\n",
        "    for i in range(3):\n",
        "        ax[1, i].imshow(irms[i+1, :, :], **kwargs)\n",
        "\n",
        "    for i in range(2):\n",
        "        for j in range(3):\n",
        "            ax[i, j].grid(False)\n",
        "            ax[i, j].axis('off')\n",
        "            ax[i, j].set_xticks([])\n",
        "            ax[i, j].set_yticks([])\n",
        "\n",
        "    ax[0, 0].set_title('IRM T1')\n",
        "    ax[1, 0].set_title('IRM Gado')\n",
        "    ax[1, 1].set_title('IRM T2')\n",
        "    ax[1, 2].set_title('IRM Flair')\n",
        "    ax[0, 1].set_title('Ground Truth Seg')\n",
        "    ax[0, 2].set_title('Predicted Seg')\n",
        "    fig.canvas.draw()\n",
        "\n",
        "    return fig\n",
        "\n",
        "class SegmentationDataset(torch.utils.data.Dataset):\n",
        "    'Generates data for torch'\n",
        "\n",
        "    def __init__(self, files_list, data_path, modalities=['t1', 't2', 't1ce', 'flair'], transform=None):\n",
        "        super(SegmentationDataset, self).__init__()\n",
        "        self.files_list = files_list\n",
        "        self.transform = transform\n",
        "        self.data_path = data_path\n",
        "        self.modalities = modalities\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        'Get a patient given idx'\n",
        "        patient = self.files_list[idx]\n",
        "\n",
        "        # Load the patient's modalities and segmentation masks\n",
        "        irm, mask = self.load(patient)\n",
        "        sample = (irm, mask)\n",
        "\n",
        "        # Apply data transformation\n",
        "        if self.transform:\n",
        "            irm, mask = self.transform(sample)\n",
        "        return (irm, mask, patient)\n",
        "\n",
        "    def load(self, ID):\n",
        "\n",
        "        patient, z_slice = ID\n",
        "        patient_path = os.path.join(self.data_path, patient)\n",
        "\n",
        "        # Get all modalities for the given slice\n",
        "        irm = []\n",
        "        for modality in self.modalities:\n",
        "            file_name = \"{patient}_{modality}_z_{z_slice}.nii.gz\".format(patient=patient, modality=modality, z_slice=z_slice)\n",
        "            path = os.path.join(patient_path, file_name)\n",
        "            irm.append(load_sitk(path))\n",
        "        irm = np.stack(irm, axis=0)\n",
        "\n",
        "        # Get the segmentation mask for the given slice\n",
        "        seg_name = \"{patient}_seg_z_{z_slice}.nii.gz\".format(patient=patient, z_slice=z_slice)\n",
        "        mask_path = os.path.join(patient_path, seg_name)\n",
        "        mask = load_sitk(mask_path)\n",
        "        mask[mask == 4] = 3\n",
        "\n",
        "        # Convert segmentation mask to one-hot encoding\n",
        "        label = 4\n",
        "        mask = mask.astype(np.int16)\n",
        "        mask = np.rollaxis(np.eye(label, dtype=np.uint8)[mask], -1, 0)\n",
        "        return irm, mask\n",
        "\n",
        "\n",
        "# Load the split, generate the IDs list\n",
        "datasets_path ='./GEP1/datasets/'\n",
        "csv_path = './GEP1/data/tumor_count.csv'\n",
        "\n",
        "# The tumour percentage is the percentage of tumour in an image. It's a threshold\n",
        "# that is used when selecting relevant slice indexes in a patient's images.\n",
        "tumour_percentage = 0.5\n",
        "train_split, val_split, test_split = load_split(datasets_path)\n",
        "\n",
        "(train_IDs, val_IDs, test_IDs) = generate_IDs(train_split, val_split, test_split, tumour_percentage, csv_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3x2uH6IVHbJ"
      },
      "source": [
        "## 4.b. Creating instances of the `SegmentationDataset` class for each split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLUqBzZ20vJH",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# No data augmentation implemented yet.\n",
        "train_Dataset = SegmentationDataset(train_IDs, data_path=data_path)\n",
        "val_Dataset = SegmentationDataset(val_IDs, data_path=data_path)\n",
        "test_Dataset = SegmentationDataset(test_IDs, data_path=data_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eXLezjAVHbK",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "source": [
        "The following cell calls for a sample of the training set. Running `train_Dataset[0]` actually calls the `__getitem__` method of the `SegmentationDataset` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvXjeUK4VHbL",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "input_modalities, segmentation_mask, patient = train_Dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GLHlL7QvVHbM",
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(\"Shape of the input:\", input_modalities.shape)\n",
        "print(\"Shape of the segmentation masks:\", segmentation_mask.shape)\n",
        "print(\"Patient identification:\", patient[0])\n",
        "print(\"Selected slice:\", patient[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivb7gvj9VHbO",
        "tags": []
      },
      "source": [
        "## 4.c. Create the `DataLoader` that will be used during training\n",
        "\n",
        "For each split, you need to specify:\n",
        "- the batch size with the `batch_size` argument\n",
        "- whether to shuffle your dataset when feeding batches to the model using the `shuffle` argument\n",
        "- whether to drop the last incomplete batch, if the dataset size is not divisible by the batch size, using the `drop_last` argument. This parameter is particularly useful when working with multiprocessing (`num_workers` > 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdhN9-SfVHbQ",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the batch size\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_Dataset,\n",
        "                                           batch_size=batch_size, shuffle=True,\n",
        "                                           drop_last=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_Dataset,\n",
        "                                         batch_size=batch_size, shuffle=False,\n",
        "                                         drop_last=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_Dataset,\n",
        "                                          batch_size=1, shuffle=False,\n",
        "                                          drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y-dKzlyVHbR"
      },
      "source": [
        "# **5. Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8BiTvbsAKAh"
      },
      "source": [
        "**Tensorboard** : This part is used to plot the prediction of the network during the training and study its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbL3St5dVHbT"
      },
      "source": [
        "## 5.a. Loss function, optimizer and hyperparameters\n",
        "\n",
        "Here you need to choose:\n",
        "- the loss function used to optimize the model (see [here](https://pytorch.org/docs/stable/nn.html#loss-functions)),\n",
        "- the optimizer (see [here](https://pytorch.org/docs/stable/optim.html))\n",
        "- all the hyperparameters: learning rate, weight decay ...\n",
        "\n",
        "\n",
        ">In our application, you can start by :\n",
        ">- choosing the `Adam` optimizer\n",
        ">- coding your own custom loss function as the dice loss\n",
        "\n",
        "\n",
        "### Exersise 2 - Implement the dice loss\n",
        "\n",
        "![dice_loss](https://i.stack.imgur.com/Usv5J.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXuDCj_bJuu_"
      },
      "outputs": [],
      "source": [
        "def dice_loss(input, target):\n",
        "    iflat = torch.flatten(input.float())\n",
        "    tflat = torch.flatten(target.float())\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return loss\n",
        "\n",
        "def mean_dice_loss(input, target):\n",
        "    channels = list(range(target.shape[1]))\n",
        "    loss = 0\n",
        "    for channel in channels:\n",
        "        dice = dice_loss(input[:, channel, ...],\n",
        "                         target[:, channel, ...])\n",
        "        loss += dice\n",
        "    return loss / len(channels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccumlRADVHbX"
      },
      "source": [
        "## 5.b. Instantiate your model\n",
        "\n",
        "You need to specify:\n",
        "- the number of input channels of the model `n_channels` which should be equal to the number of modalities, so 4 modalities\n",
        "- the number of segmentation classes `n_classes` = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "o2_ojZwTVHbY",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "n_modalities = 4\n",
        "n_classes = 4\n",
        "model = UNet(n_channels=n_modalities, n_classes=n_classes) # Create model\n",
        "model.cuda() # move model to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3T1rsaWVHbW"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-2\n",
        "\n",
        "criterion = mean_dice_loss # Choose loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # Choose optimize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOzLyZKWVHbZ"
      },
      "source": [
        "## 5.c. Training loop for a single epoch\n",
        "\n",
        "Here you should complete the `train_loop` function, which goes over the whole dataset only once, so correspond to one epoch.\n",
        "\n",
        "When the model is in training mode `model.training == True`, the function should perform backpropagation and parameters' updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AHqde7wdTkM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "def train_loop(loader, model, criterion, optimizer, writer, epoch):\n",
        "\n",
        "    logging_mode = 'Train' if model.training else 'Val'\n",
        "    if model.training:print('training')\n",
        "\n",
        "    epoch_time_sum, epoch_loss_sum = [], []\n",
        "\n",
        "    for i, sample in enumerate(loader, 1):\n",
        "        start = time.time()\n",
        "        # Take variable\n",
        "        (irms, masks, patients) = sample\n",
        "        # print(irms.shape) # Batch * Number of Modalities * Width * Height\n",
        "\n",
        "        # Put variables to GPU\n",
        "        irms = irms.float().cuda()\n",
        "        masks = masks.float().cuda()\n",
        "\n",
        "        # compute model prediction\n",
        "        pred_masks = model(irms)\n",
        "\n",
        "        # compute loss\n",
        "        dice_loss = criterion(pred_masks, masks)\n",
        "\n",
        "        # If in training mode ...\n",
        "        if model.training:\n",
        "            # Initialize optimizer gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "            # Perform backpropagation\n",
        "            dice_loss.backward()\n",
        "            # Update the model's trainable parameters using the computed gradients\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "        # Compute elapsed time\n",
        "        batch_time = time.time() - start\n",
        "\n",
        "        epoch_time_sum += [batch_time]\n",
        "        epoch_loss_sum += [dice_loss.item()]\n",
        "\n",
        "        average_time = np.mean(epoch_time_sum)\n",
        "        average_loss = np.mean(epoch_loss_sum)\n",
        "\n",
        "        if i % print_frequency == 0:\n",
        "            print_summary(epoch + 1, i, len(loader), dice_loss, batch_time,\n",
        "                          average_loss, average_time, logging_mode)\n",
        "        step = epoch*len(loader) + i\n",
        "        writer.add_scalar(logging_mode + '_dice', dice_loss.item(),step)\n",
        "\n",
        "\n",
        "\n",
        "    writer.add_scalar(logging_mode + '_global_loss', np.mean(epoch_loss_sum), epoch)\n",
        "\n",
        "\n",
        "    # Save some figures to monitor segmentation quality\n",
        "    n_modalities = irms.shape[0]\n",
        "    irms = to_numpy(irms)\n",
        "    masks = to_numpy(masks)\n",
        "    pred_masks = to_numpy(pred_masks)\n",
        "\n",
        "    for batch in range(n_modalities):\n",
        "        fig = plot(irms[batch, ...], masks[batch, ...], pred_masks[batch, ...])\n",
        "        writer.add_figure(logging_mode + str(batch), fig, epoch)\n",
        "    writer.flush()\n",
        "    return np.mean(epoch_loss_sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPelDIO4VHbb"
      },
      "source": [
        "## 5.d. Perform the training\n",
        "\n",
        "You will use **Tensorboard** to monitor the decrease of the loss funciton/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErxK8fLnahBn"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir './GEP1/save/tensorboard_logs/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiIfIBakVHbc",
        "tags": []
      },
      "outputs": [],
      "source": [
        "save_path = \"./GEP1/save/\"\n",
        "session_name = 'Test_session' + '_' + time.strftime('%m.%d %Hh%M')\n",
        "model_path = save_path + 'models/' + session_name + '/'\n",
        "# Configure tensorboard\n",
        "session_name = 'Test_session' + '_' + time.strftime('%m.%d %Hh%M')\n",
        "tensorboard_folder = save_path + 'tensorboard_logs/'\n",
        "log_dir = tensorboard_folder + session_name + '/'\n",
        "\n",
        "if not os.path.isdir(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "writer = torch.utils.tensorboard.SummaryWriter(log_dir)\n",
        "# Training parameters\n",
        "epochs = 5\n",
        "print_frequency = 10\n",
        "save_frequency = 1\n",
        "save_model = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxyPwfvYw5d5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "    print('******** Epoch [{}/{}]  ********'.format(epoch+1, epochs+1))\n",
        "    print(session_name)\n",
        "\n",
        "    # train for one epoch\n",
        "    model.train()\n",
        "    print('Training')\n",
        "    train_loop(train_loader, model, criterion, optimizer, writer, epoch)\n",
        "\n",
        "    # evaluate on validation set\n",
        "    print('Validation')\n",
        "    with torch.no_grad():   # Disable gradient computation (faster and saves memory)\n",
        "        model.eval()        # Disable Dropout and BatchNormalization\n",
        "        val_loss = train_loop(val_loader, model, criterion, optimizer, writer, epoch)\n",
        "\n",
        "    if save_model and epoch % save_frequency == 0:\n",
        "        save_checkpoint({'epoch': epoch,\n",
        "                        'state_dict': model.state_dict(),\n",
        "                         'val_loss': val_loss,\n",
        "                         'optimizer': optimizer.state_dict()}, model_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
