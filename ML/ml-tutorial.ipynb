{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMkHLNWr2cXk"
      },
      "source": [
        "<table>\n",
        "<tr height=\"150px\">\n",
        "<th>\n",
        "<img height=\"80px\" margin=\"20px\" src='https://www.archimedesai.gr/images/logo_en.svg' />\n",
        "</th>\n",
        "<th>\n",
        "<img height=\"150px\" src='https://stergioc.github.io/assets/img/logos.png' />\n",
        "</th>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "<h1>Introduction to Machine Learning (Hands-on Tutorial)</h1>\n",
        "<h3>Stergios CHRISTODOULIDIS & Maria VAKALOPOULOU</h3>\n",
        "\n",
        "\n",
        "[![ML-tutorial](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/stergioc/BioMed-AI-Summer-School/blob/master/ML/ml-tutorial.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRx93d2o5UoT"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this tutorial we will investigate a simple pipeline for extracting radiomic\n",
        "features from MRI images and then we will use them for a classification task to discriminate between low-grade (LGG) and high-grade (HGG) glioma patients. The data are retrieved from the [BraTS dataset](https://www.med.upenn.edu/cbica/brats2019/data.html) and have been already lightly preprocessed for this tutorial.\n",
        "\n",
        "### Documentation Links\n",
        "- [SimpleITK](https://simpleitk.readthedocs.io/en/master/) - Used for loading and processing radiological data.\n",
        "- [pyradiomics](https://pyradiomics.readthedocs.io/en/latest/) - Used for extracting features from radiological data.\n",
        "- [Pandas](https://pandas.pydata.org/docs/) - Used for data organization\n",
        "- [scikit-learn](https://scikit-learn.org/stable/user_guide.html) - Used for training machine learning models\n",
        "\n",
        "\n",
        "In the following code block the necessary packages will be installed and imported. Moreover, the different files that are required for the purposes of this tutorial will be downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5RWME4K2hfu"
      },
      "outputs": [],
      "source": [
        "# Installing necessary libraries\n",
        "!pip install SimpleITK pyradiomics\n",
        "\n",
        "# Downloading the required files\n",
        "!wget https://nextcloud.centralesupelec.fr/s/jCeq7GrMGyyYKSn/download -O data.zip\n",
        "!unzip -o data.zip\n",
        "\n",
        "# Importing the necessary libaries\n",
        "import glob\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import SimpleITK as sitk\n",
        "import matplotlib.pyplot as plt\n",
        "# This module is used for interaction with pyradiomics\n",
        "from radiomics import featureextractor  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3nyAWoC3CYG"
      },
      "source": [
        "# Part I - Loading and Visualization of data\n",
        "\n",
        "In this first part we will load and visualize the data we downloaded. The data are MRI images of the brain with tumoral regions. For each patient a number of different modalities are available (T1, T2, T1ce, FLAIR) together with a segmentation map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWUzhJuhO__v"
      },
      "outputs": [],
      "source": [
        "# Retrieves the directories of the downloaded MRI images\n",
        "t1_file_list = sorted(glob.glob('data/mri/**/**/*_t1.nii.gz'))\n",
        "t2_file_list = sorted(glob.glob('data/mri/**/**/*_t2.nii.gz'))\n",
        "t1ce_file_list = sorted(glob.glob('data/mri/**/**/*_t1ce.nii.gz'))\n",
        "flair_file_list = sorted(glob.glob('data/mri/**/**/*_flair.nii.gz'))\n",
        "seg_file_list = sorted(glob.glob('data/mri/**/**/*_seg.nii.gz'))\n",
        "\n",
        "# Organize all the data in a DataFrame\n",
        "database = pd.DataFrame({\n",
        "    'T1': t1_file_list,\n",
        "    'T2': t2_file_list,\n",
        "    'T1ce': t1ce_file_list,\n",
        "    'FLAIR': flair_file_list,\n",
        "    'Seg': seg_file_list\n",
        "})\n",
        "database.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtKzqjIMjpZw"
      },
      "outputs": [],
      "source": [
        "IDX = 10\n",
        "\n",
        "# Load a single MRI file using SimpleITK\n",
        "img_sitk = sitk.ReadImage(database.at[IDX,'T1'])\n",
        "img_np = sitk.GetArrayFromImage(img_sitk)\n",
        "\n",
        "# Load a single MRI file using SimpleITK\n",
        "seg_sitk = sitk.ReadImage(database.at[IDX,'Seg'])\n",
        "seg_np = sitk.GetArrayFromImage(seg_sitk)\n",
        "\n",
        "# Shows the dimensions of the MRI image\n",
        "print(f\"Shape of the image: {img_np.shape}\")\n",
        "print(f\"Shape of the segmentation: {seg_np.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX7ndz3tR7CO"
      },
      "source": [
        "There are $155$ slices in the volume, where each slice is $240\\times240$ pixel image. Similary the segmentation image have the same dimensions. Let's visualise some of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-sHpbV7S8KN"
      },
      "outputs": [],
      "source": [
        "# Visualize a single slide of the MRI with the segmentation mask overlaid\n",
        "SLIDE = 80\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(img_np[SLIDE,...], cmap='gray')\n",
        "plt.imshow(seg_np[SLIDE,...], alpha=0.5)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8V76AkFEWGdY"
      },
      "outputs": [],
      "source": [
        "# Visualize multiple slices of the MRI image with the segmentation mask overlaid\n",
        "fig, axes = plt.subplots(ncols=5, nrows=4, figsize=(7, 5))\n",
        "\n",
        "for i in range(0,img_np.shape[0],8):\n",
        "  axes.ravel()[i//8].set_title(f'Slice: {i}')\n",
        "  axes.ravel()[i//8].imshow(img_np[i,...], cmap='gray')\n",
        "  axes.ravel()[i//8].imshow(seg_np[i,...], alpha=0.5)\n",
        "  axes.ravel()[i//8].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxX-8ZXLaqOE"
      },
      "source": [
        "As already mentioned for this specific database there are multiple modalities available, let's visualize all the modalities for a single patient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWogxAi8apzi"
      },
      "outputs": [],
      "source": [
        "# Load all MRI protocols and the segmentation\n",
        "t1_np = sitk.GetArrayFromImage(sitk.ReadImage(database.at[IDX,'T1']))\n",
        "t2_np = sitk.GetArrayFromImage(sitk.ReadImage(database.at[IDX,'T2']))\n",
        "t1ce_np = sitk.GetArrayFromImage(sitk.ReadImage(database.at[IDX,'T1ce']))\n",
        "flair_np = sitk.GetArrayFromImage(sitk.ReadImage(database.at[IDX,'FLAIR']))\n",
        "seg_np = sitk.GetArrayFromImage(sitk.ReadImage(database.at[IDX,'Seg']))\n",
        "\n",
        "all_images = {\n",
        "    'T1': t1_np, \n",
        "    'T2': t2_np, \n",
        "    'T1ce': t1ce_np, \n",
        "    'FLAIR': flair_np, \n",
        "    'Segmentation': seg_np\n",
        "}\n",
        "\n",
        "# Visualize all the protocols\n",
        "fig, axes = plt.subplots(ncols=5, figsize=(15, 5))\n",
        "for i, (k,img) in enumerate(all_images.items()):\n",
        "  colormap = None if i==4 else 'gray'\n",
        "  axes[i].imshow(img[SLIDE,...], cmap=colormap)\n",
        "  axes[i].set_title(k)\n",
        "  axes[i].axis('off')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8eRFlPndbGW"
      },
      "source": [
        "# Part II - Data Preprocessing\n",
        "\n",
        "To stabilise the downstream feature extraction and analysis, we first normalise the data. For input image $I$, we create normalised image $I_z$ by normalising each pixel $x_{ij}$ according to,\n",
        "\n",
        "$$I_z^{ij} = \\frac{I^{ij} - \\mu_I}{\\sigma_I}.$$\n",
        "\n",
        "Because of the abundance of background values in each volume, we compute $\\mu_I$ and $\\sigma_I$ only over the pixels of $I$ above a certain threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vybRV-keD6a"
      },
      "outputs": [],
      "source": [
        "# Histogram of the pixel values for each modality\n",
        "plt.hist([\n",
        "    t1_np.ravel(),\n",
        "    t2_np.ravel(),\n",
        "    t1ce_np.ravel(),\n",
        "    flair_np.ravel()\n",
        "    ], label=['T1', 'T2', 'T1ce','FLAIR'],\n",
        "    histtype='stepfilled', alpha=0.3, density=True, bins=40, ec=\"k\")\n",
        "\n",
        "plt.title('Pixel Values Histogram for all Modalities')\n",
        "plt.xlabel('Intensity Value')\n",
        "plt.ylabel('Pixel Count')\n",
        "plt.legend()\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDMwy9o2mfJA"
      },
      "source": [
        "### Excerise 1 - MRI Image Loading and Standardization: \n",
        "\n",
        "Write a function `load_img_norm` that will load and normalize  an image in order to be used in the following parts of the tutorial. The function will take as an input arguments the image `image_dir` and the `threshold`. The function will need to return the normalized sitk object and a numpy array by using only the elements of the volume with values larger than the threshold.\n",
        "\n",
        "\n",
        "You can use the necessary function from the previous code blocks as well as the following functions: \n",
        " - `<SimpleITK object> = sitk.GetImageFromArray(<numpy array>)`\n",
        " - `<SimpleITK object>.CopyInformation(<SimpleITK object>)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC4detwOgsdJ"
      },
      "outputs": [],
      "source": [
        "def load_img_norm(image_dir, threshold=0):\n",
        "  ### START CODE HERE ###\n",
        "\n",
        "  ### END CODE HERE ###\n",
        "  return normalized_sitk, normalized_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_ZjRql4hzSw"
      },
      "outputs": [],
      "source": [
        "# Histogram of the pixel values for each modality\n",
        "IDX = 10\n",
        "plt.hist([\n",
        "    load_img_norm(database.at[IDX,'T1'])[1].ravel(),\n",
        "    load_img_norm(database.at[IDX,'T2'])[1].ravel(),\n",
        "    load_img_norm(database.at[IDX,'T1ce'])[1].ravel(),\n",
        "    load_img_norm(database.at[IDX,'FLAIR'])[1].ravel(),\n",
        "    ], label=['T1_norm', 'T2_norm', 'T1ce_norm','FLAIR_norm'],\n",
        "    histtype='stepfilled', alpha=0.3, density=True, bins=40, ec=\"k\")\n",
        "\n",
        "plt.title('Pixel Values Histogram for all Modalities')\n",
        "plt.xlabel('Intensity Value')\n",
        "plt.ylabel('Pixel Count')\n",
        "plt.legend()\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9NMM2VpqfVo"
      },
      "source": [
        "# Part III - Radiomics Feature Extraction\n",
        "\n",
        "### Excerise 2 - Radiomics Feature Extraction: \n",
        "\n",
        "Now that we have prepared our image loaders, we can proceed to extract the radiomics features. We use the default settings of the extractor. Let us extract features for a single patient, under the T1 modality, for the full tumour region.\n",
        "\n",
        "You can use the excecute function from the `RadiomicsFeatureExtractor()` class that it is available in the `featureextractor` that we have already loaded.\n",
        "\n",
        "Check the documentation [here](https://pyradiomics.readthedocs.io/en/latest/radiomics.html#radiomics.featureextractor.RadiomicsFeatureExtractor)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpEQyLocqer_"
      },
      "outputs": [],
      "source": [
        "### START CODE HERE ###\n",
        "\n",
        "### END CODE HERE ###\n",
        "\n",
        "print(pd.Series(result))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6SBHYzcf2m50"
      },
      "source": [
        "# Part IV - Feature Exploration and Visualization\n",
        "\n",
        "The first step in applying machine learning is to understand the data, so as to be able to identify a good target to learn, as well as an appropriate learning algorithm among many alternatives.\n",
        "\n",
        "The analysis above has been applied on few patients only. Since our time in this practical session is limited, the features on the entire BraTS dataset has been extracted into a csv file located at `./data/radiomics.csv`. This file contains one row per patient per input modality (T1, T1ce, T2, flair). With the feaures from the full cohort, we can begin to explore the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y99h8bNr2998"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('data/radiomics.csv')\n",
        "display(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5cAUMkQ3VUK"
      },
      "source": [
        "### Pairwise joint distributions\n",
        "\n",
        "We can see the join distribution of any pair of columns/attributes/variables/features by using the pairplot function. We do this for the first 5 features. Each datapoint is a patient and the colour indicates the disease class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTeXzFQq3Vub"
      },
      "outputs": [],
      "source": [
        "# filter one sequence type and a segmentation type (you can change the sequence type and segmentation type)\n",
        "d = data[(data['sequence']=='t1ce')].iloc[:, 2:8] \n",
        "sns.pairplot(d, hue='label', size=2.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSbfYnuy8NzP"
      },
      "source": [
        "### Feature Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLhPEskE3j3v"
      },
      "outputs": [],
      "source": [
        "# filter one sequence type and a segmentation type (you can change the sequence type and segmentation type)\n",
        "d = data[(data['sequence']=='t1')].iloc[:, 3:]\n",
        "sns.clustermap(d.corr())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyez6gVI8ZRs"
      },
      "source": [
        "# Part V - Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOl08xWd8jNy"
      },
      "outputs": [],
      "source": [
        "# Reshapes the dataframe such as each row to have all the features for a patient\n",
        "data = data.pivot_table(index=['patient', 'label'],\n",
        "                                columns=['sequence'],\n",
        "                                values=data.columns[3:])\n",
        "data.columns = ['_'.join(col).strip() for col in data.columns.values]\n",
        "data.reset_index(level=1, inplace=True)\n",
        "\n",
        "# Convert LGG into class 0 and HGG into class 1\n",
        "data.loc[data['label'] == 'HGG', 'label'] = 1\n",
        "data.loc[data['label'] == 'LGG', 'label'] = 0\n",
        "\n",
        "display(data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zZQKAMWp9KDz"
      },
      "source": [
        "### Train-Test Splitting\n",
        "\n",
        "Let's now use <code>train_test_split</code> from the function in scikit-learn to divide features data (x_data) and target data (y_data) even further into train and test. Here we will have 30% of the data for the test set. It is also a good practice to define a random state for reproducible results.\n",
        "\n",
        "*Note: Stratify parameter in the function makes the equal proportion in the split. For example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y_data will make sure that your random split has 25% of 0's and 75% of 1'*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kk0wsVOG9KU8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_data, y_data = data.drop(columns='label'), data['label'].astype(int).to_numpy()\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data ,test_size = 0.3, random_state=123, stratify=y_data)\n",
        "\n",
        "print(f'x_train shape: {x_train.shape}')\n",
        "print(f'x_test shape: {x_test.shape}')\n",
        "print(f'y_train shape: {y_train.shape}')\n",
        "print(f'y_test shape: {y_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4cBp9_k84Jq"
      },
      "source": [
        "### Exercise 3 - Radiomics Features Preprocessing\n",
        "\n",
        "As we have already identified the differnt radiomics features are following different distributions ($\\mu$,$\\sigma$). It is important for most classifiers all the features to fall on similar value ranges. For this purpose we will need to normalize our features. \n",
        "\n",
        "You can use the available preprocessing tools that are available within the scikit-learn library for this purpose, e.g., [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) or [MinMax](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html).\n",
        "\n",
        "\n",
        "\n",
        "*Tips: You can apply multiple functions as a [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) using the pipeline class. See [here](https://scikit-learn.org/stable/modules/preprocessing.html) for more preprocessing guidelines.*\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3KgPKz6_jui"
      },
      "outputs": [],
      "source": [
        "### START CODE HERE ###\n",
        "\n",
        "### END CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfjHEZFd-qeE"
      },
      "source": [
        "### Exersise 4 - Train a classifier\n",
        "\n",
        "With all the features extracted and preprocessed, we can proceed to training our first machine learning model. You can select any model from the scikit-learn library and train it.\n",
        "\n",
        "You can find all the available models [here](https://scikit-learn.org/stable/supervised_learning.html).\n",
        "\n",
        "*Tips: Start simple using the default parameters of a [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier or a [random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SO0wi80h9cVO"
      },
      "outputs": [],
      "source": [
        "### START CODE HERE ###\n",
        "\n",
        "### END CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWU4NF_v-EOM"
      },
      "source": [
        "### Performance Measure\n",
        "\n",
        "Once the model is trained, i.e. `fit` function is done, it can be used to classify any input sample with the correct shape. Notably, training and validation accuracies can be obtained with other performance indicators:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkVo9V3Q9yy9"
      },
      "outputs": [],
      "source": [
        "accuracy_train = clf.score(X=x_train_norm, y=y_train)\n",
        "probs = clf.predict_proba(x_train)\n",
        "accuracy_test = clf.score(X=x_test_norm, y=y_test)\n",
        "print(f'Training accuracy: {accuracy_train}')\n",
        "print(f'Test accuracy: {accuracy_test}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GSz6DGi_4fT"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "predictions = clf.predict(x_test_norm)\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['LGG','HGG'])\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
